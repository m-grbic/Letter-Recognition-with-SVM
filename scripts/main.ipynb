{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, KFold\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are NaNs in dataset\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>letter</th>\n",
       "      <th>xbox</th>\n",
       "      <th>ybox</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>onpix</th>\n",
       "      <th>xbar</th>\n",
       "      <th>ybar</th>\n",
       "      <th>x2bar</th>\n",
       "      <th>y2bar</th>\n",
       "      <th>xybar</th>\n",
       "      <th>x2ybar</th>\n",
       "      <th>xy2bar</th>\n",
       "      <th>xedge</th>\n",
       "      <th>xedgey</th>\n",
       "      <th>yedge</th>\n",
       "      <th>yedgex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>T</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>D</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>N</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>G</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>S</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>B</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>J</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>M</td>\n",
       "      <td>11</td>\n",
       "      <td>15</td>\n",
       "      <td>13</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  letter  xbox   ybox   width   height  onpix   xbar   ybar   x2bar  y2bar   \\\n",
       "0      T      2      8       3       5       1      8     13      0       6   \n",
       "1      I      5     12       3       7       2     10      5      5       4   \n",
       "2      D      4     11       6       8       6     10      6      2       6   \n",
       "3      N      7     11       6       6       3      5      9      4       6   \n",
       "4      G      2      1       3       1       1      8      6      6       6   \n",
       "5      S      4     11       5       8       3      8      8      6       9   \n",
       "6      B      4      2       5       4       4      8      7      6       6   \n",
       "7      A      1      1       3       2       1      8      2      2       2   \n",
       "8      J      2      2       4       4       2     10      6      2       6   \n",
       "9      M     11     15      13       9       7     13      2      6       2   \n",
       "\n",
       "   xybar   x2ybar  xy2bar  xedge   xedgey  yedge   yedgex  \n",
       "0       6      10       8       0       8       0       8  \n",
       "1      13       3       9       2       8       4      10  \n",
       "2      10       3       7       3       7       3       9  \n",
       "3       4       4      10       6      10       2       8  \n",
       "4       6       5       9       1       7       5      10  \n",
       "5       5       6       6       0       8       9       7  \n",
       "6       7       6       6       2       8       7      10  \n",
       "7       8       2       8       1       6       2       7  \n",
       "8      12       4       8       1       6       1       7  \n",
       "9      12       1       9       8       1       1       8  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../dataset/letter-recognition.csv')\n",
    "\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check for missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are no NaNs in dataset\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "if(df.isnull().values.any()):\n",
    "    print(\"There are NaNs in dataset\")\n",
    "else:\n",
    "    print(\"There are no NaNs in dataset\")\n",
    "    \n",
    "    \n",
    "x_val = np.arange(0,26)\n",
    "x_tic = [ chr(ord('A') + l) for l in x_val]\n",
    "y_val = [(df['letter'] == x_tic[i]).sum() for i in range(26)]\n",
    "\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.bar(x_val, y_val, color='r')\n",
    "plt.xticks(x_val, x_tic)\n",
    "plt.title('Number of occurrences of each letter')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset is balanced and there is no need for oversample or undersample some letters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions of input data: (20000, 16)\n",
      "Dimensions of output data: (20000,)\n"
     ]
    }
   ],
   "source": [
    "# Input data\n",
    "X = df.iloc[:,1:].to_numpy()\n",
    "# Output data\n",
    "y = df.iloc[:, 0].to_numpy()\n",
    "\n",
    "print(\"Dimensions of input data: \" + str(X.shape))\n",
    "print(\"Dimensions of output data: \" + str(y.shape))\n",
    "\n",
    "# Split data on train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Enumerate output data\n",
    "encoder = LabelEncoder().fit(y_train)\n",
    "y_train = encoder.transform(y_train)\n",
    "y_test = encoder.transform(y_test)\n",
    "\n",
    "# Normalize input data\n",
    "mu = np.mean(X_train, axis=0)\n",
    "sigma = np.std(X_train, axis=0)\n",
    "X_train = (X_train - mu)/sigma\n",
    "X_test = (X_test - mu)/sigma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = SVC(C=1, kernel='rbf')\n",
    "\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train mean accuracy: 0.9588\n",
      "Test mean accuracy: 0.9500\n"
     ]
    }
   ],
   "source": [
    "print(\"Train mean accuracy: %.4f\" %model.score(X_train, y_train))\n",
    "print(\"Test mean accuracy: %.4f\" %model.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  80 out of  80 | elapsed: 28.1min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=KFold(n_splits=5, random_state=42, shuffle=True),\n",
       "             estimator=SVC(),\n",
       "             param_grid=[{'C': [1, 10, 100, 1000],\n",
       "                          'gamma': [0.1, 0.01, 0.001, 0.0001]}],\n",
       "             return_train_score=True, scoring='accuracy', verbose=1)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folds = KFold(n_splits = 5, shuffle = True, random_state = 42)\n",
    "\n",
    "hyper_params = [ {'gamma': [1e-1, 1e-2, 1e-3, 1e-4], 'C': [1, 10, 100, 1000]}]\n",
    "\n",
    "model = SVC(kernel=\"rbf\")\n",
    "\n",
    "model_cv = GridSearchCV(estimator = model, \n",
    "                        param_grid = hyper_params, \n",
    "                        scoring= 'accuracy', \n",
    "                        cv = folds, \n",
    "                        verbose = 1,\n",
    "                        return_train_score=True)      \n",
    "\n",
    "model_cv.fit(X_train, y_train)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_C</th>\n",
       "      <th>param_gamma</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.519309</td>\n",
       "      <td>0.243302</td>\n",
       "      <td>2.276535</td>\n",
       "      <td>0.097599</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'C': 1, 'gamma': 0.1}</td>\n",
       "      <td>0.948125</td>\n",
       "      <td>0.955937</td>\n",
       "      <td>0.951250</td>\n",
       "      <td>...</td>\n",
       "      <td>0.950937</td>\n",
       "      <td>0.003023</td>\n",
       "      <td>5</td>\n",
       "      <td>0.972266</td>\n",
       "      <td>0.969688</td>\n",
       "      <td>0.970547</td>\n",
       "      <td>0.970781</td>\n",
       "      <td>0.972109</td>\n",
       "      <td>0.971078</td>\n",
       "      <td>0.000978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.838894</td>\n",
       "      <td>0.056331</td>\n",
       "      <td>3.035604</td>\n",
       "      <td>0.092435</td>\n",
       "      <td>1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'C': 1, 'gamma': 0.01}</td>\n",
       "      <td>0.830625</td>\n",
       "      <td>0.843750</td>\n",
       "      <td>0.845938</td>\n",
       "      <td>...</td>\n",
       "      <td>0.840188</td>\n",
       "      <td>0.006446</td>\n",
       "      <td>11</td>\n",
       "      <td>0.853359</td>\n",
       "      <td>0.847812</td>\n",
       "      <td>0.848359</td>\n",
       "      <td>0.847031</td>\n",
       "      <td>0.852031</td>\n",
       "      <td>0.849719</td>\n",
       "      <td>0.002502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.389809</td>\n",
       "      <td>0.247960</td>\n",
       "      <td>3.969394</td>\n",
       "      <td>0.126676</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001</td>\n",
       "      <td>{'C': 1, 'gamma': 0.001}</td>\n",
       "      <td>0.684688</td>\n",
       "      <td>0.698125</td>\n",
       "      <td>0.697187</td>\n",
       "      <td>...</td>\n",
       "      <td>0.691125</td>\n",
       "      <td>0.005744</td>\n",
       "      <td>14</td>\n",
       "      <td>0.695781</td>\n",
       "      <td>0.696797</td>\n",
       "      <td>0.695391</td>\n",
       "      <td>0.690859</td>\n",
       "      <td>0.694844</td>\n",
       "      <td>0.694734</td>\n",
       "      <td>0.002040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23.357129</td>\n",
       "      <td>2.597080</td>\n",
       "      <td>4.669637</td>\n",
       "      <td>0.314672</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>{'C': 1, 'gamma': 0.0001}</td>\n",
       "      <td>0.255625</td>\n",
       "      <td>0.254688</td>\n",
       "      <td>0.235937</td>\n",
       "      <td>...</td>\n",
       "      <td>0.237875</td>\n",
       "      <td>0.020991</td>\n",
       "      <td>16</td>\n",
       "      <td>0.267422</td>\n",
       "      <td>0.261719</td>\n",
       "      <td>0.245391</td>\n",
       "      <td>0.256953</td>\n",
       "      <td>0.218594</td>\n",
       "      <td>0.250016</td>\n",
       "      <td>0.017302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.966719</td>\n",
       "      <td>0.104052</td>\n",
       "      <td>2.225039</td>\n",
       "      <td>0.057946</td>\n",
       "      <td>10</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'C': 10, 'gamma': 0.1}</td>\n",
       "      <td>0.966875</td>\n",
       "      <td>0.972187</td>\n",
       "      <td>0.970625</td>\n",
       "      <td>...</td>\n",
       "      <td>0.969313</td>\n",
       "      <td>0.002213</td>\n",
       "      <td>1</td>\n",
       "      <td>0.997266</td>\n",
       "      <td>0.997578</td>\n",
       "      <td>0.997344</td>\n",
       "      <td>0.997188</td>\n",
       "      <td>0.997422</td>\n",
       "      <td>0.997359</td>\n",
       "      <td>0.000134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3.596705</td>\n",
       "      <td>0.116364</td>\n",
       "      <td>2.269284</td>\n",
       "      <td>0.075982</td>\n",
       "      <td>10</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'C': 10, 'gamma': 0.01}</td>\n",
       "      <td>0.911875</td>\n",
       "      <td>0.922500</td>\n",
       "      <td>0.914062</td>\n",
       "      <td>...</td>\n",
       "      <td>0.912813</td>\n",
       "      <td>0.006474</td>\n",
       "      <td>7</td>\n",
       "      <td>0.931719</td>\n",
       "      <td>0.926953</td>\n",
       "      <td>0.928359</td>\n",
       "      <td>0.929453</td>\n",
       "      <td>0.929531</td>\n",
       "      <td>0.929203</td>\n",
       "      <td>0.001567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6.544964</td>\n",
       "      <td>1.436084</td>\n",
       "      <td>4.396717</td>\n",
       "      <td>0.759401</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>{'C': 10, 'gamma': 0.001}</td>\n",
       "      <td>0.810000</td>\n",
       "      <td>0.815312</td>\n",
       "      <td>0.816875</td>\n",
       "      <td>...</td>\n",
       "      <td>0.816125</td>\n",
       "      <td>0.003985</td>\n",
       "      <td>12</td>\n",
       "      <td>0.827969</td>\n",
       "      <td>0.822187</td>\n",
       "      <td>0.825000</td>\n",
       "      <td>0.822031</td>\n",
       "      <td>0.828125</td>\n",
       "      <td>0.825062</td>\n",
       "      <td>0.002656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>12.823213</td>\n",
       "      <td>0.422066</td>\n",
       "      <td>4.812083</td>\n",
       "      <td>0.198552</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>{'C': 10, 'gamma': 0.0001}</td>\n",
       "      <td>0.683125</td>\n",
       "      <td>0.696562</td>\n",
       "      <td>0.697500</td>\n",
       "      <td>...</td>\n",
       "      <td>0.690438</td>\n",
       "      <td>0.005898</td>\n",
       "      <td>15</td>\n",
       "      <td>0.694766</td>\n",
       "      <td>0.696953</td>\n",
       "      <td>0.695391</td>\n",
       "      <td>0.691094</td>\n",
       "      <td>0.693906</td>\n",
       "      <td>0.694422</td>\n",
       "      <td>0.001939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5.122094</td>\n",
       "      <td>0.223478</td>\n",
       "      <td>2.305950</td>\n",
       "      <td>0.051677</td>\n",
       "      <td>100</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'C': 100, 'gamma': 0.1}</td>\n",
       "      <td>0.965000</td>\n",
       "      <td>0.972187</td>\n",
       "      <td>0.972187</td>\n",
       "      <td>...</td>\n",
       "      <td>0.968938</td>\n",
       "      <td>0.003287</td>\n",
       "      <td>3</td>\n",
       "      <td>0.999922</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999922</td>\n",
       "      <td>0.999844</td>\n",
       "      <td>0.999922</td>\n",
       "      <td>0.999922</td>\n",
       "      <td>0.000049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4.025817</td>\n",
       "      <td>0.206156</td>\n",
       "      <td>1.745369</td>\n",
       "      <td>0.247500</td>\n",
       "      <td>100</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'C': 100, 'gamma': 0.01}</td>\n",
       "      <td>0.942813</td>\n",
       "      <td>0.954063</td>\n",
       "      <td>0.945937</td>\n",
       "      <td>...</td>\n",
       "      <td>0.946562</td>\n",
       "      <td>0.004889</td>\n",
       "      <td>6</td>\n",
       "      <td>0.978594</td>\n",
       "      <td>0.977266</td>\n",
       "      <td>0.978125</td>\n",
       "      <td>0.977500</td>\n",
       "      <td>0.977344</td>\n",
       "      <td>0.977766</td>\n",
       "      <td>0.000513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>4.068416</td>\n",
       "      <td>0.224724</td>\n",
       "      <td>2.389273</td>\n",
       "      <td>0.083412</td>\n",
       "      <td>100</td>\n",
       "      <td>0.001</td>\n",
       "      <td>{'C': 100, 'gamma': 0.001}</td>\n",
       "      <td>0.859688</td>\n",
       "      <td>0.871250</td>\n",
       "      <td>0.865625</td>\n",
       "      <td>...</td>\n",
       "      <td>0.864812</td>\n",
       "      <td>0.006527</td>\n",
       "      <td>9</td>\n",
       "      <td>0.880391</td>\n",
       "      <td>0.876172</td>\n",
       "      <td>0.876875</td>\n",
       "      <td>0.879062</td>\n",
       "      <td>0.881797</td>\n",
       "      <td>0.878859</td>\n",
       "      <td>0.002106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>5.659871</td>\n",
       "      <td>0.471224</td>\n",
       "      <td>4.023002</td>\n",
       "      <td>1.287205</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>{'C': 100, 'gamma': 0.0001}</td>\n",
       "      <td>0.806875</td>\n",
       "      <td>0.810625</td>\n",
       "      <td>0.812187</td>\n",
       "      <td>...</td>\n",
       "      <td>0.812000</td>\n",
       "      <td>0.004795</td>\n",
       "      <td>13</td>\n",
       "      <td>0.822891</td>\n",
       "      <td>0.816719</td>\n",
       "      <td>0.820156</td>\n",
       "      <td>0.816875</td>\n",
       "      <td>0.823516</td>\n",
       "      <td>0.820031</td>\n",
       "      <td>0.002873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>5.142497</td>\n",
       "      <td>0.264461</td>\n",
       "      <td>2.277478</td>\n",
       "      <td>0.109027</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'C': 1000, 'gamma': 0.1}</td>\n",
       "      <td>0.965625</td>\n",
       "      <td>0.972500</td>\n",
       "      <td>0.972500</td>\n",
       "      <td>...</td>\n",
       "      <td>0.969250</td>\n",
       "      <td>0.003191</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>4.941753</td>\n",
       "      <td>0.360626</td>\n",
       "      <td>1.588066</td>\n",
       "      <td>0.082101</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'C': 1000, 'gamma': 0.01}</td>\n",
       "      <td>0.945625</td>\n",
       "      <td>0.959375</td>\n",
       "      <td>0.955313</td>\n",
       "      <td>...</td>\n",
       "      <td>0.952375</td>\n",
       "      <td>0.005018</td>\n",
       "      <td>4</td>\n",
       "      <td>0.997109</td>\n",
       "      <td>0.997031</td>\n",
       "      <td>0.996563</td>\n",
       "      <td>0.996484</td>\n",
       "      <td>0.997344</td>\n",
       "      <td>0.996906</td>\n",
       "      <td>0.000330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>4.651122</td>\n",
       "      <td>0.341675</td>\n",
       "      <td>1.678936</td>\n",
       "      <td>0.102696</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.001</td>\n",
       "      <td>{'C': 1000, 'gamma': 0.001}</td>\n",
       "      <td>0.898438</td>\n",
       "      <td>0.911875</td>\n",
       "      <td>0.903438</td>\n",
       "      <td>...</td>\n",
       "      <td>0.903562</td>\n",
       "      <td>0.007040</td>\n",
       "      <td>8</td>\n",
       "      <td>0.931016</td>\n",
       "      <td>0.928906</td>\n",
       "      <td>0.929141</td>\n",
       "      <td>0.928281</td>\n",
       "      <td>0.930781</td>\n",
       "      <td>0.929625</td>\n",
       "      <td>0.001080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>4.818303</td>\n",
       "      <td>0.411973</td>\n",
       "      <td>2.765860</td>\n",
       "      <td>0.556696</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>{'C': 1000, 'gamma': 0.0001}</td>\n",
       "      <td>0.840625</td>\n",
       "      <td>0.855313</td>\n",
       "      <td>0.845000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.846313</td>\n",
       "      <td>0.006125</td>\n",
       "      <td>10</td>\n",
       "      <td>0.863984</td>\n",
       "      <td>0.856641</td>\n",
       "      <td>0.858203</td>\n",
       "      <td>0.859531</td>\n",
       "      <td>0.861953</td>\n",
       "      <td>0.860063</td>\n",
       "      <td>0.002623</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time param_C  \\\n",
       "0        4.519309      0.243302         2.276535        0.097599       1   \n",
       "1        4.838894      0.056331         3.035604        0.092435       1   \n",
       "2       10.389809      0.247960         3.969394        0.126676       1   \n",
       "3       23.357129      2.597080         4.669637        0.314672       1   \n",
       "4        4.966719      0.104052         2.225039        0.057946      10   \n",
       "5        3.596705      0.116364         2.269284        0.075982      10   \n",
       "6        6.544964      1.436084         4.396717        0.759401      10   \n",
       "7       12.823213      0.422066         4.812083        0.198552      10   \n",
       "8        5.122094      0.223478         2.305950        0.051677     100   \n",
       "9        4.025817      0.206156         1.745369        0.247500     100   \n",
       "10       4.068416      0.224724         2.389273        0.083412     100   \n",
       "11       5.659871      0.471224         4.023002        1.287205     100   \n",
       "12       5.142497      0.264461         2.277478        0.109027    1000   \n",
       "13       4.941753      0.360626         1.588066        0.082101    1000   \n",
       "14       4.651122      0.341675         1.678936        0.102696    1000   \n",
       "15       4.818303      0.411973         2.765860        0.556696    1000   \n",
       "\n",
       "   param_gamma                        params  split0_test_score  \\\n",
       "0          0.1        {'C': 1, 'gamma': 0.1}           0.948125   \n",
       "1         0.01       {'C': 1, 'gamma': 0.01}           0.830625   \n",
       "2        0.001      {'C': 1, 'gamma': 0.001}           0.684688   \n",
       "3       0.0001     {'C': 1, 'gamma': 0.0001}           0.255625   \n",
       "4          0.1       {'C': 10, 'gamma': 0.1}           0.966875   \n",
       "5         0.01      {'C': 10, 'gamma': 0.01}           0.911875   \n",
       "6        0.001     {'C': 10, 'gamma': 0.001}           0.810000   \n",
       "7       0.0001    {'C': 10, 'gamma': 0.0001}           0.683125   \n",
       "8          0.1      {'C': 100, 'gamma': 0.1}           0.965000   \n",
       "9         0.01     {'C': 100, 'gamma': 0.01}           0.942813   \n",
       "10       0.001    {'C': 100, 'gamma': 0.001}           0.859688   \n",
       "11      0.0001   {'C': 100, 'gamma': 0.0001}           0.806875   \n",
       "12         0.1     {'C': 1000, 'gamma': 0.1}           0.965625   \n",
       "13        0.01    {'C': 1000, 'gamma': 0.01}           0.945625   \n",
       "14       0.001   {'C': 1000, 'gamma': 0.001}           0.898438   \n",
       "15      0.0001  {'C': 1000, 'gamma': 0.0001}           0.840625   \n",
       "\n",
       "    split1_test_score  split2_test_score  ...  mean_test_score  \\\n",
       "0            0.955937           0.951250  ...         0.950937   \n",
       "1            0.843750           0.845938  ...         0.840188   \n",
       "2            0.698125           0.697187  ...         0.691125   \n",
       "3            0.254688           0.235937  ...         0.237875   \n",
       "4            0.972187           0.970625  ...         0.969313   \n",
       "5            0.922500           0.914062  ...         0.912813   \n",
       "6            0.815312           0.816875  ...         0.816125   \n",
       "7            0.696562           0.697500  ...         0.690438   \n",
       "8            0.972187           0.972187  ...         0.968938   \n",
       "9            0.954063           0.945937  ...         0.946562   \n",
       "10           0.871250           0.865625  ...         0.864812   \n",
       "11           0.810625           0.812187  ...         0.812000   \n",
       "12           0.972500           0.972500  ...         0.969250   \n",
       "13           0.959375           0.955313  ...         0.952375   \n",
       "14           0.911875           0.903438  ...         0.903562   \n",
       "15           0.855313           0.845000  ...         0.846313   \n",
       "\n",
       "    std_test_score  rank_test_score  split0_train_score  split1_train_score  \\\n",
       "0         0.003023                5            0.972266            0.969688   \n",
       "1         0.006446               11            0.853359            0.847812   \n",
       "2         0.005744               14            0.695781            0.696797   \n",
       "3         0.020991               16            0.267422            0.261719   \n",
       "4         0.002213                1            0.997266            0.997578   \n",
       "5         0.006474                7            0.931719            0.926953   \n",
       "6         0.003985               12            0.827969            0.822187   \n",
       "7         0.005898               15            0.694766            0.696953   \n",
       "8         0.003287                3            0.999922            1.000000   \n",
       "9         0.004889                6            0.978594            0.977266   \n",
       "10        0.006527                9            0.880391            0.876172   \n",
       "11        0.004795               13            0.822891            0.816719   \n",
       "12        0.003191                2            1.000000            1.000000   \n",
       "13        0.005018                4            0.997109            0.997031   \n",
       "14        0.007040                8            0.931016            0.928906   \n",
       "15        0.006125               10            0.863984            0.856641   \n",
       "\n",
       "    split2_train_score  split3_train_score  split4_train_score  \\\n",
       "0             0.970547            0.970781            0.972109   \n",
       "1             0.848359            0.847031            0.852031   \n",
       "2             0.695391            0.690859            0.694844   \n",
       "3             0.245391            0.256953            0.218594   \n",
       "4             0.997344            0.997188            0.997422   \n",
       "5             0.928359            0.929453            0.929531   \n",
       "6             0.825000            0.822031            0.828125   \n",
       "7             0.695391            0.691094            0.693906   \n",
       "8             0.999922            0.999844            0.999922   \n",
       "9             0.978125            0.977500            0.977344   \n",
       "10            0.876875            0.879062            0.881797   \n",
       "11            0.820156            0.816875            0.823516   \n",
       "12            1.000000            1.000000            1.000000   \n",
       "13            0.996563            0.996484            0.997344   \n",
       "14            0.929141            0.928281            0.930781   \n",
       "15            0.858203            0.859531            0.861953   \n",
       "\n",
       "    mean_train_score  std_train_score  \n",
       "0           0.971078         0.000978  \n",
       "1           0.849719         0.002502  \n",
       "2           0.694734         0.002040  \n",
       "3           0.250016         0.017302  \n",
       "4           0.997359         0.000134  \n",
       "5           0.929203         0.001567  \n",
       "6           0.825062         0.002656  \n",
       "7           0.694422         0.001939  \n",
       "8           0.999922         0.000049  \n",
       "9           0.977766         0.000513  \n",
       "10          0.878859         0.002106  \n",
       "11          0.820031         0.002873  \n",
       "12          1.000000         0.000000  \n",
       "13          0.996906         0.000330  \n",
       "14          0.929625         0.001080  \n",
       "15          0.860063         0.002623  \n",
       "\n",
       "[16 rows x 22 columns]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_results = pd.DataFrame(model_cv.cv_results_)\n",
    "cv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best test score is 0.9693125 corresponding to hyperparameters {'C': 10, 'gamma': 0.1}\n"
     ]
    }
   ],
   "source": [
    "best_score = model_cv.best_score_\n",
    "best_hyperparams = model_cv.best_params_\n",
    "\n",
    "print(\"The best test score is {0} corresponding to hyperparameters {1}\".format(best_score, best_hyperparams))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimal hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train mean accuracy: 0.9971\n",
      "Test mean accuracy: 0.9788\n"
     ]
    }
   ],
   "source": [
    "model = SVC(C=10, kernel='rbf', gamma=0.1)\n",
    "model.fit(X_train, y_train)\n",
    "print(\"Train mean accuracy: %.4f\" %model.score(X_train, y_train))\n",
    "print(\"Test mean accuracy: %.4f\" %model.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = (encoder.inverse_transform(model.predict(X_test))).astype(str)\n",
    "df_out = pd.DataFrame(y_pred, columns=['prediction'])\n",
    "df_out.to_csv(\"../prediction/submission.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
